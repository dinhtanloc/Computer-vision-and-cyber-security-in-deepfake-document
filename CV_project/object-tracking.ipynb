{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    "----\n",
    "#### NOTE: It is probably a good idea to restart the kernel if you ever run these cells, as the tracking algo can sometimes get caught in a loop with your camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ShiTomasi corner detection (good features to track paper)\n",
    "corner_track_params = dict(maxCorners = 10,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Lucas Kanade Optical Flow\n",
    "\n",
    "Detect the motion of specific points or the aggregated motion of regions by modifying the winSize argument. This determines the integration window size. Small windows are more sensitive to noise and may miss larger motions. Large windows will “survive” an occlusion.\n",
    "\n",
    "The integration appears smoother with the larger window size.\n",
    "\n",
    "criteria has two here - the max number (10 above) of iterations and epsilon (0.03 above). More iterations means a more exhaustive search, and a smaller epsilon finishes earlier. These are primarily useful in exchanging speed vs accuracy, but mainly stay the same.\n",
    "\n",
    "When maxLevel is 0, it is the same algorithm without using pyramids (ie, calcOpticalFlowLK). Pyramids allow finding optical flow at various resolutions of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (200,200),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Grab the very first frame of the stream\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Grab a grayscale image (We will refer to this as the previous frame)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Grabbing the corners\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n",
    "\n",
    "# Create a matching mask of the previous frame for drawing on later\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Grab current frame\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # Grab gray scale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Optical Flow on the Gray Scale Frame\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    # Using the returned status array (the status output)\n",
    "    # status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
    "    # the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "\n",
    "    # Use ravel to get points to draw lines and circles\n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new,y_new = new.ravel()\n",
    "        x_prev,y_prev = prev.ravel()\n",
    "        \n",
    "        # Lines will be drawn using the mask created from the first frame\n",
    "        mask = cv2.line(mask, (int(x_new),int(y_new)),(int(x_prev),int(y_prev)), (0,255,0), 3)\n",
    "        \n",
    "        # Draw red circles at corner points\n",
    "        frame = cv2.circle(frame,(int(x_new),int(y_new)),8,(0,0,255),-1)\n",
    "    \n",
    "    # Display the image along with the mask we drew the line on.\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function cartToPolar>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cartToPolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanShift Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "\n",
    "\n",
    "# Set Up the Initial Tracking Window\n",
    "\n",
    "\n",
    "# We will first detect the face and set that as our starting box.\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "face_rects = face_cascade.detectMultiScale(frame) \n",
    "\n",
    "# Convert this list of a single array to a tuple of (x,y,w,h)\n",
    "(face_x,face_y,w,h) = tuple(face_rects[0]) \n",
    "track_window = (face_x,face_y,w,h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[face_y:face_y+h, face_x:face_x+w]\n",
    "\n",
    "\n",
    "# Use the HSV Color Mapping\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Find histogram to backproject the target on each frame for calculation of meanshit\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "\n",
    "# Normalize the histogram array values given a min of 0 and max of 255\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Grab the Frame in HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Calculate the Back Projection based off the roi_hist created earlier\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # Apply meanshift to get the new coordinates of the rectangle\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # Draw the new rectangle on the image\n",
    "        x,y,w,h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255),5)\n",
    "        \n",
    "        cv2.imshow('img2',img2)\n",
    "        \n",
    "        \n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamShift Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16844\\3933706065.py:59: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  pts = np.int0(pts)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "# Capture a video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "\n",
    "\n",
    "# Set Up the Initial Tracking Window\n",
    "\n",
    "\n",
    "# We will first detect the face and set that as our starting box.\n",
    "face_cascade = cv2.CascadeClassifier('DATA/haarcascades/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_cascade.detectMultiScale(frame) \n",
    "\n",
    "# Convert this list of a single array to a tuple of (x,y,w,h)\n",
    "(face_x,face_y,w,h) = tuple(face_rects[0]) \n",
    "track_window = (face_x,face_y,w,h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[face_y:face_y+h, face_x:face_x+w]\n",
    "\n",
    "\n",
    "# Use the HSV Color Mapping\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Find histogram to backproject the target on each frame for calculation of meanshit\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "\n",
    "# Normalize the histogram array values given a min of 0 and max of 255\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Grab the Frame in HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Calculate the Back Projection based off the roi_hist created earlier\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        #########################################################\n",
    "        #########################################################\n",
    "        ########## CAM SHIFT ####################################\n",
    "        ########################################################\n",
    "        #######################################################\n",
    "        \n",
    "        # Apply Camshift to get the new coordinates of the rectangle\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # Draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame,[pts],True, (0,0,255),5)\n",
    "        cv2.imshow('img2',img2)\n",
    "        \n",
    "        ########################################################\n",
    "        #######################################################\n",
    "        ########################################################\n",
    "        #######################################################\n",
    "        \n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking APIs ( Built-in with OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def ask_for_tracker():\n",
    "    print(\"Welcome! What Tracker API would you like to use?\")\n",
    "    print(\"Enter 0 for BOOSTING: \")\n",
    "    print(\"Enter 1 for MIL: \")\n",
    "    print(\"Enter 2 for KCF: \")\n",
    "    print(\"Enter 3 for TLD: \")\n",
    "    print(\"Enter 4 for MEDIANFLOW: \")\n",
    "    choice = input(\"Please select your tracker: \")\n",
    "    \n",
    "    if choice == '0':\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "    if choice == '1':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if choice == '2':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if choice == '3':\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "    if choice == '4':\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "\n",
    "\n",
    "    return tracker\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)\n",
    "\n",
    "# In 4.9.0.80 or newer, you can check available trackers like this:\n",
    "print([x for x in dir(cv2.Tracker) if 'create' in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n"
     ]
    }
   ],
   "source": [
    "tracker = ask_for_tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.TrackerMIL 00000203923F9C50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cv2.TrackerMIL'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tracker).split()[1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n"
     ]
    }
   ],
   "source": [
    "tracker = ask_for_tracker()\n",
    "tracker_name = str(tracker).split()[1:][0]\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read first frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "\n",
    "# Special function allows us to draw on the very first frame our desired ROI\n",
    "roi = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ret = tracker.init(frame, roi)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # Update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi variable is a tuple of 4 floats\n",
    "    # We need each value and we need them as integers\n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    # Draw Rectangle as Tracker moves\n",
    "    if success:\n",
    "        # Tracking success\n",
    "        p1 = (x, y)\n",
    "        p2 = (x+w, y+h)\n",
    "        cv2.rectangle(frame, p1, p2, (0,255,0), 3)\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Failure to Detect Tracking!!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, tracker_name, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),3);\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(tracker_name, frame)\n",
    "\n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
